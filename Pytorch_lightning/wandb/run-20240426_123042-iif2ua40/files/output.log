[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
C:\Users\tobia\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\tobia\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_320_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_320_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name  | Type       | Params
-------------------------------------
0 | model | FasterRCNN | 19.4 M
-------------------------------------
19.3 M    Trainable params
58.9 K    Non-trainable params
19.4 M    Total params
77.545    Total estimated model params size (MB)
C:\Users\tobia\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
C:\Users\tobia\AppData\Local\Temp\ipykernel_26876\3609768078.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  image = torch.tensor(image, dtype=torch.float32).div(255)
C:\Users\tobia\AppData\Local\Temp\ipykernel_26876\3609768078.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  targ = {key: torch.tensor(val) for key, val in targ.items()}
C:\Users\tobia\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\pytorch_lightning\utilities\data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
C:\Users\tobia\AppData\Local\Temp\ipykernel_26876\3609768078.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  image = torch.tensor(image, dtype=torch.float32).div(255)
C:\Users\tobia\AppData\Local\Temp\ipykernel_26876\3609768078.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  targ = {key: torch.tensor(val) for key, val in targ.items()}
C:\Users\tobia\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Using hurtig model
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s][{'boxes': tensor([[113.0000, 203.0000, 352.2280, 334.8250]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([0], device='cuda:0'), 'area': tensor([31536.2344], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}, {'boxes': tensor([[260.0000, 190.0000, 409.6520, 315.7760]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([1], device='cuda:0'), 'area': tensor([18822.6309], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}, {'boxes': tensor([[ 94.0000, 206.0000, 532.9530, 383.8990]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([2], device='cuda:0'), 'area': tensor([78089.2969], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}, {'boxes': tensor([[  4.0000, 166.0000,  87.8310, 239.7580],
        [  0.0000,   0.0000,  71.2690,  56.0560],
        [186.0000,  63.0000, 337.6880, 125.6910],
        [178.0000, 313.0000, 523.3080, 503.1160]], device='cuda:0'), 'labels': tensor([1, 1, 1, 1], device='cuda:0'), 'image_id': tensor([3, 3, 3, 3], device='cuda:0'), 'area': tensor([ 6183.2065,  3995.0549,  9509.4717, 65648.5703], device='cuda:0'), 'iscrowd': tensor([0, 0, 0, 0], device='cuda:0')}]
--------------------
[{'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}, {'boxes': tensor([[  0.0000, 163.7512, 111.2293, 356.3948]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.9546], device='cuda:0')}]
Sanity Checking DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.46it/s][{'boxes': tensor([[265.0000, 238.0000, 358.0030, 345.0620]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([4], device='cuda:0'), 'area': tensor([9957.0869], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}, {'boxes': tensor([[119.0000, 286.0000, 385.0000, 441.0000],
        [374.0000, 210.0000, 639.6260, 313.0000]], device='cuda:0'), 'labels': tensor([1, 1], device='cuda:0'), 'image_id': tensor([5, 5], device='cuda:0'), 'area': tensor([41230.0000, 27359.4766], device='cuda:0'), 'iscrowd': tensor([0, 0], device='cuda:0')}, {'boxes': tensor([[167.0000, 247.0000, 410.7170, 394.0070]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([6], device='cuda:0'), 'area': tensor([35828.1055], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}, {'boxes': tensor([[243., 250., 416., 374.]], device='cuda:0'), 'labels': tensor([1], device='cuda:0'), 'image_id': tensor([7], device='cuda:0'), 'area': tensor([21452.], device='cuda:0'), 'iscrowd': tensor([0], device='cuda:0')}]
--------------------
[{'boxes': tensor([[264.7362, 309.9513, 289.3699, 341.3243]], device='cuda:0'), 'labels': tensor([16], device='cuda:0'), 'scores': tensor([0.1528], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}, {'boxes': tensor([], device='cuda:0', size=(0, 4)), 'labels': tensor([], device='cuda:0', dtype=torch.int64), 'scores': tensor([], device='cuda:0')}]










